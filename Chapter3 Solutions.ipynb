{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  30 | elapsed:  5.2min remaining:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  30 | elapsed:  6.1min remaining:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:  7.7min remaining:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:  8.0min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  8.3min remaining:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'algorithm': ['brute'], 'n_neighbors': [2, 4, 6],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()\n",
    "X, y = mnist[\"data\"], mnist[\"target\"] \n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "#6 combinations of hyperparameters\n",
    "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [2, 4, 6], 'algorithm':['brute']}\n",
    "]\n",
    "#Train with 5 folds for 30 rounds\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=10, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'brute', 'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716166666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 2\n",
    "from scipy.ndimage.interpolation import shift\n",
    "def shift_image(image, dx, dy):\n",
    "    image = image.reshape((28, 28))\n",
    "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
    "    return shifted_image.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_train[500]\n",
    "shifted_image_down = shift_image(image, 0, 5)\n",
    "shifted_image_left = shift_image(image, -5, 0)\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Original\", fontsize=14)\n",
    "plt.imshow(image.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.subplot(132)\n",
    "plt.title(\"down\", fontsize=14)\n",
    "plt.imshow(shifted_image_down.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.subplot(133)\n",
    "plt.title(\"left\", fontsize=14)\n",
    "plt.imshow(shifted_image_left.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = [image for image in X_train]\n",
    "y_train_augmented = [label for label in y_train]\n",
    "\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "    for image, label in zip(X_train, y_train):\n",
    "        X_train_augmented.append(shift_image(image, dx, dy))\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
    "X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "y_train_augmented = y_train_augmented[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(**grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(X_train_augmented, y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 3\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Loading data\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Which data is null?\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Num attributes\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline for preprocessing. We select numerical or categorical\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline for numerical\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"Age\", \"SibSp\", \"Parch\", \"Fare\"])),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.    ,  1.    ,  0.    ,  7.25  ],\n",
       "       [38.    ,  1.    ,  0.    , 71.2833],\n",
       "       [26.    ,  0.    ,  0.    ,  7.925 ],\n",
       "       ...,\n",
       "       [28.    ,  1.    ,  2.    , 23.45  ],\n",
       "       [26.    ,  0.    ,  0.    , 30.    ],\n",
       "       [32.    ,  0.    ,  0.    ,  7.75  ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical attributes being turned into numerical ones\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline to select/transform categorical into numerical\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"Pclass\", \"Sex\", \"Embarked\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featureunion allows us to input put categorical and numerical at same time\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.,  1.,  0., ...,  0.,  0.,  1.],\n",
       "       [38.,  1.,  0., ...,  1.,  0.,  0.],\n",
       "       [26.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ...,\n",
       "       [28.,  1.,  2., ...,  0.,  0.,  1.],\n",
       "       [26.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [32.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(gamma=\"auto\")\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess_pipeline.transform(test_data)\n",
    "y_pred = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7329588014981274"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8126466916354558"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\n",
    "forest_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "def fetch_spam_data(spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", HAM_URL), (\"spam.tar.bz2\", SPAM_URL)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=SPAM_PATH)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Emails and parse\n",
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate ham from spam\n",
    "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate different email structures\n",
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email)\n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counts how many structures in an email\n",
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 2408),\n",
       " ('multipart(text/plain, application/pgp-signature)', 66),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count structures in ham \n",
    "structures_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 218),\n",
       " ('text/html', 183),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 20),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Coutn structures in spam\n",
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(ham_emails + spam_emails)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML><HEAD><TITLE></TITLE><META http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1252\"><STYLE>A:link {TEX-DECORATION: none}A:active {TEXT-DECORATION: none}A:visited {TEXT-DECORATION: none}A:hover {COLOR: #0033ff; TEXT-DECORATION: underline}</STYLE><META content=\"MSHTML 6.00.2713.1100\" name=\"GENERATOR\"></HEAD>\n",
      "<BODY text=\"#000000\" vLink=\"#0033ff\" link=\"#0033ff\" bgColor=\"#CCCC99\"><TABLE borderColor=\"#660000\" cellSpacing=\"0\" cellPadding=\"0\" border=\"0\" width=\"100%\"><TR><TD bgColor=\"#CCCC99\" valign=\"top\" colspan=\"2\" height=\"27\">\n",
      "<font size=\"6\" face=\"Arial, Helvetica, sans-serif\" color=\"#660000\">\n",
      "<b>OTC</b></font></TD></TR><TR><TD height=\"2\" bgcolor=\"#6a694f\">\n",
      "<font size=\"5\" face=\"Times New Roman, Times, serif\" color=\"#FFFFFF\">\n",
      "<b>&nbsp;Newsletter</b></font></TD><TD height=\"2\" bgcolor=\"#6a694f\"><div align=\"right\"><font color=\"#FFFFFF\">\n",
      "<b>Discover Tomorrow's Winners&nbsp;</b></font></div></TD></TR><TR><TD height=\"25\" colspan=\"2\" bgcolor=\"#CCCC99\"><table width=\"100%\" border=\"0\"  ...\n"
     ]
    }
   ],
   "source": [
    "html_spam_emails = [email for email in X_train[y_train==1]\n",
    "                    if get_email_structure(email) == \"text/html\"]\n",
    "sample_html_spam = html_spam_emails[7]\n",
    "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
      "Put CBYI on your watch list, acquire a position TODAY.\n",
      "REASONS TO INVEST IN CBYI\n",
      "A profitable company and is on track to beat ALL earnings estimates!\n",
      "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
      "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
      "RAPIDLY GROWING INDUSTRY\n",
      "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billi ...\n"
     ]
    }
   ],
   "source": [
    "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in email and outputs plaintext\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Wat ...\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(sample_html_spam)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "#stemmer function \n",
    "import nltk\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "    print(word, \"=>\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts urls from text\n",
    "try:\n",
    "    import google.colab\n",
    "    !pip install -q -U urlextract\n",
    "except ImportError:\n",
    "    pass # not running on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer that counts the amount of each word in an email\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'chuck': 1, 'murcko': 1, 'wrote': 1, 'stuff': 1, 'yawn': 1, 'r': 1}),\n",
       "       Counter({'the': 11, 'of': 9, 'and': 8, 'all': 3, 'christian': 3, 'to': 3, 'by': 3, 'jefferson': 2, 'i': 2, 'have': 2, 'superstit': 2, 'one': 2, 'on': 2, 'been': 2, 'ha': 2, 'half': 2, 'rogueri': 2, 'teach': 2, 'jesu': 2, 'some': 1, 'interest': 1, 'quot': 1, 'http': 1, 'www': 1, 'postfun': 1, 'com': 1, 'pfp': 1, 'worboi': 1, 'html': 1, 'thoma': 1, 'examin': 1, 'known': 1, 'word': 1, 'do': 1, 'not': 1, 'find': 1, 'in': 1, 'our': 1, 'particular': 1, 'redeem': 1, 'featur': 1, 'they': 1, 'are': 1, 'alik': 1, 'found': 1, 'fabl': 1, 'mytholog': 1, 'million': 1, 'innoc': 1, 'men': 1, 'women': 1, 'children': 1, 'sinc': 1, 'introduct': 1, 'burnt': 1, 'tortur': 1, 'fine': 1, 'imprison': 1, 'what': 1, 'effect': 1, 'thi': 1, 'coercion': 1, 'make': 1, 'world': 1, 'fool': 1, 'other': 1, 'hypocrit': 1, 'support': 1, 'error': 1, 'over': 1, 'earth': 1, 'six': 1, 'histor': 1, 'american': 1, 'john': 1, 'e': 1, 'remsburg': 1, 'letter': 1, 'william': 1, 'short': 1, 'again': 1, 'becom': 1, 'most': 1, 'pervert': 1, 'system': 1, 'that': 1, 'ever': 1, 'shone': 1, 'man': 1, 'absurd': 1, 'untruth': 1, 'were': 1, 'perpetr': 1, 'upon': 1, 'a': 1, 'larg': 1, 'band': 1, 'dupe': 1, 'import': 1, 'led': 1, 'paul': 1, 'first': 1, 'great': 1, 'corrupt': 1}),\n",
       "       Counter({'number': 5, 'http': 4, 'yahoo': 4, 's': 3, 'group': 3, 'com': 3, 'to': 3, 'in': 2, 'forteana': 2, 'martin': 2, 'an': 2, 'and': 2, 'memri': 2, 'we': 2, 'is': 2, 'unsubscrib': 2, 'y': 1, 'adamson': 1, 'wrote': 1, 'for': 1, 'altern': 1, 'rather': 1, 'more': 1, 'factual': 1, 'base': 1, 'rundown': 1, 'on': 1, 'hamza': 1, 'career': 1, 'includ': 1, 'hi': 1, 'belief': 1, 'that': 1, 'all': 1, 'non': 1, 'muslim': 1, 'yemen': 1, 'should': 1, 'be': 1, 'murder': 1, 'outright': 1, 'org': 1, 'bin': 1, 'articl': 1, 'cgi': 1, 'page': 1, 'archiv': 1, 'area': 1, 'ia': 1, 'id': 1, 'ianumb': 1, 'know': 1, 'how': 1, 'unbias': 1, 'don': 1, 't': 1, 'www': 1, 'guardian': 1, 'co': 1, 'uk': 1, 'elsewher': 1, 'journalist': 1, 'stori': 1, 'html': 1, 'rob': 1, 'sponsor': 1, 'dvd': 1, 'free': 1, 'p': 1, 'join': 1, 'now': 1, 'us': 1, 'click': 1, 'ptnumberybb': 1, 'nxieaa': 1, 'mvfiaa': 1, 'numbergsolb': 1, 'tm': 1, 'from': 1, 'thi': 1, 'send': 1, 'email': 1, 'egroup': 1, 'your': 1, 'use': 1, 'of': 1, 'subject': 1, 'doc': 1, 'info': 1, 'term': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts word count to vector, output sparse matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.most_common_ = most_common\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [112,  11,   9,   8,   3,   1,   0,   1,   3,   0,   1],\n",
       "       [ 92,   0,   1,   2,   3,   4,   5,   3,   1,   4,   2]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors\n",
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'and': 3,\n",
       " 'to': 4,\n",
       " 'http': 5,\n",
       " 'number': 6,\n",
       " 'com': 7,\n",
       " 'all': 8,\n",
       " 'yahoo': 9,\n",
       " 'in': 10}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ranks words most often to least often occurring\n",
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming whole data set\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=10, n_jobs=-1)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 97.89%\n",
      "Recall: 97.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Travis\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "log_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = log_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And thats it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
